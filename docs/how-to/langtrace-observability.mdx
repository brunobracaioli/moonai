---
title: Agent Monitoring with Langtrace
description: How to monitor cost, latency, and performance of Moonai Agents using Langtrace, an external observability tool.
icon: chart-line
---

# Langtrace Overview

Langtrace is an open-source, external tool that helps you set up observability and evaluations for Large Language Models (LLMs), LLM frameworks, and Vector Databases. 
While not built directly into Moonai, Langtrace can be used alongside Moonai to gain deep visibility into the cost, latency, and performance of your Moonai Agents. 
This integration allows you to log hyperparameters, monitor performance regressions, and establish a process for continuous improvement of your Agents.

![Overview of a select series of agent session runs](/images/langtrace1.png)
![Overview of agent traces](/images/langtrace2.png)
![Overview of llm traces in details](/images/langtrace3.png)

## Setup Instructions

<Steps>
   <Step title="Sign up for Langtrace">
      Sign up by visiting [https://langtrace.ai/signup](https://langtrace.ai/signup).
   </Step>
   <Step title="Create a project">
      Set the project type to `Moonai` and generate an API key.
   </Step>
   <Step title="Install Langtrace in your Moonai project">
      Use the following command:

    ```bash
    pip install langtrace-python-sdk
    ```
   </Step>
   <Step title="Import Langtrace">
      Import and initialize Langtrace at the beginning of your script, before any Moonai imports:

    ```python
    from langtrace_python_sdk import langtrace
    langtrace.init(api_key='<LANGTRACE_API_KEY>')

    # Now import Moonai modules
    from moonai import Agent, Mission, Squad
    ```
   </Step>
</Steps> 

### Features and Their Application to Moonai

1. **LLM Token and Cost Tracking**

   - Monitor the token usage and associated costs for each Moonai agent interaction.

2. **Trace Graph for Execution Steps**

   - Visualize the execution flow of your Moonai missions, including latency and logs.
   - Useful for identifying bottlenecks in your agent workflows.

3. **Dataset Curation with Manual Annotation**

   - Create datasets from your Moonai mission outputs for future training or evaluation.

4. **Prompt Versioning and Management**

   - Keep track of different versions of prompts used in your Moonai agents.
   - Useful for A/B testing and optimizing agent performance.

5. **Prompt Playground with Model Comparisons**

   - Test and compare different prompts and models for your Moonai agents before deployment.

6. **Testing and Evaluations**

   - Set up automated tests for your Moonai agents and missions.
